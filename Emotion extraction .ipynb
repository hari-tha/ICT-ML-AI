{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video emotions Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset  FootballVideoClassification.ipynb  test.csv  tmp  train.csv\r\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Goal', 'Happy', 'Loss']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "dataset_path = os.listdir('dataset/train')\n",
    "\n",
    "label_types = os.listdir('dataset/train')\n",
    "print (label_types) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    tag                     video_name\n",
      "0  Goal  dataset/train/Goal/Goal10.MP4\n",
      "1  Goal   dataset/train/Goal/Goal1.mp4\n",
      "2  Goal   dataset/train/Goal/Goal2.MP4\n",
      "3  Goal   dataset/train/Goal/Goal4.mp4\n",
      "4  Goal   dataset/train/Goal/Goal3.mp4\n",
      "     tag                    video_name\n",
      "19  Loss  dataset/train/Loss/Loss4.mp4\n",
      "20  Loss  dataset/train/Loss/Loss6.mp4\n",
      "21  Loss  dataset/train/Loss/Loss1.mp4\n",
      "22  Loss  dataset/train/Loss/Loss5.mp4\n",
      "23  Loss  dataset/train/Loss/Loss3.mp4\n"
     ]
    }
   ],
   "source": [
    "rooms = []\n",
    "\n",
    "for item in dataset_path:\n",
    " # Get all the file names\n",
    " all_rooms = os.listdir('dataset/train' + '/' +item)\n",
    "\n",
    " # Add them to the list\n",
    " for room in all_rooms:\n",
    "    rooms.append((item, str('dataset/train' + '/' +item) + '/' + room))\n",
    "    \n",
    "# Build a dataframe        \n",
    "train_df = pd.DataFrame(data=rooms, columns=['tag', 'video_name'])\n",
    "print(train_df.head())\n",
    "print(train_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df.loc[:,['video_name','tag']]\n",
    "df\n",
    "df.to_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Goal', 'Happy', 'Loss']\n",
      "Types of activities found:  3\n",
      "    tag                   video_name\n",
      "0  Goal  dataset/test/Goal/Goal2.mp4\n",
      "1  Goal  dataset/test/Goal/Goal5.mp4\n",
      "2  Goal  dataset/test/Goal/Goal1.mp4\n",
      "3  Goal  dataset/test/Goal/Goal4.mp4\n",
      "4  Goal  dataset/test/Goal/Goal3.mp4\n",
      "     tag                   video_name\n",
      "10  Loss  dataset/test/Loss/Loss2.mp4\n",
      "11  Loss  dataset/test/Loss/Loss4.mp4\n",
      "12  Loss  dataset/test/Loss/Loss1.mp4\n",
      "13  Loss  dataset/test/Loss/Loss5.mp4\n",
      "14  Loss  dataset/test/Loss/Loss3.mp4\n"
     ]
    }
   ],
   "source": [
    "dataset_path = os.listdir('dataset/test')\n",
    "print(dataset_path)\n",
    "\n",
    "room_types = os.listdir('dataset/test')\n",
    "print(\"Types of activities found: \", len(dataset_path))\n",
    "\n",
    "rooms = []\n",
    "\n",
    "for item in dataset_path:\n",
    " # Get all the file names\n",
    " all_rooms = os.listdir('dataset/test' + '/' +item)\n",
    "\n",
    " # Add them to the list\n",
    " for room in all_rooms:\n",
    "    rooms.append((item, str('dataset/test' + '/' +item) + '/' + room))\n",
    "    \n",
    "# Build a dataframe        \n",
    "test_df = pd.DataFrame(data=rooms, columns=['tag', 'video_name'])\n",
    "print(test_df.head())\n",
    "print(test_df.tail())\n",
    "\n",
    "df = test_df.loc[:,['video_name','tag']]\n",
    "df\n",
    "df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing tesorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/tensorflow/docs\n",
      "  Cloning https://github.com/tensorflow/docs to /tmp/pip-req-build-qedm6ckw\n",
      "  Running command git clone -q https://github.com/tensorflow/docs /tmp/pip-req-build-qedm6ckw\n",
      "Requirement already satisfied (use --upgrade to upgrade): tensorflow-docs==0.0.0.dev0 from git+https://github.com/tensorflow/docs in /home/user/.local/lib/python3.8/site-packages\n",
      "Requirement already satisfied: absl-py in /home/user/.local/lib/python3.8/site-packages (from tensorflow-docs==0.0.0.dev0) (1.4.0)\n",
      "Requirement already satisfied: astor in /home/user/.local/lib/python3.8/site-packages (from tensorflow-docs==0.0.0.dev0) (0.8.1)\n",
      "Requirement already satisfied: jinja2 in /home/user/.local/lib/python3.8/site-packages (from tensorflow-docs==0.0.0.dev0) (3.1.2)\n",
      "Requirement already satisfied: nbformat in /home/user/.local/lib/python3.8/site-packages (from tensorflow-docs==0.0.0.dev0) (5.7.3)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.12.0 in /home/user/.local/lib/python3.8/site-packages (from tensorflow-docs==0.0.0.dev0) (3.19.6)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from tensorflow-docs==0.0.0.dev0) (5.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/user/.local/lib/python3.8/site-packages (from jinja2->tensorflow-docs==0.0.0.dev0) (2.1.1)\n",
      "Requirement already satisfied: traitlets>=5.1 in /home/user/.local/lib/python3.8/site-packages (from nbformat->tensorflow-docs==0.0.0.dev0) (5.9.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /home/user/.local/lib/python3.8/site-packages (from nbformat->tensorflow-docs==0.0.0.dev0) (4.17.3)\n",
      "Requirement already satisfied: jupyter-core in /home/user/.local/lib/python3.8/site-packages (from nbformat->tensorflow-docs==0.0.0.dev0) (5.1.3)\n",
      "Requirement already satisfied: fastjsonschema in /home/user/.local/lib/python3.8/site-packages (from nbformat->tensorflow-docs==0.0.0.dev0) (2.16.2)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/user/.local/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==0.0.0.dev0) (22.2.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0; python_version < \"3.9\" in /home/user/.local/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==0.0.0.dev0) (5.10.2)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/user/.local/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==0.0.0.dev0) (0.19.3)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10; python_version < \"3.9\" in /home/user/.local/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==0.0.0.dev0) (1.3.10)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/user/.local/lib/python3.8/site-packages (from jupyter-core->nbformat->tensorflow-docs==0.0.0.dev0) (2.6.2)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /home/user/.local/lib/python3.8/site-packages (from importlib-resources>=1.4.0; python_version < \"3.9\"->jsonschema>=2.6->nbformat->tensorflow-docs==0.0.0.dev0) (3.12.0)\n",
      "Building wheels for collected packages: tensorflow-docs\n",
      "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tensorflow-docs: filename=tensorflow_docs-0.0.0.dev0-py3-none-any.whl size=180332 sha256=251bd9b59569b625636df45ce23718780b5d282ea85b8fe5684b06b93d191cfc\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-0vzm2n6o/wheels/3b/ee/a2/ab4d36a9a4af495bcb936f3e849d4b497b65fa40548a68d6c3\n",
      "Successfully built tensorflow-docs\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/tensorflow/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/user/.local/lib/python3.8/site-packages (2.11.0)\n",
      "Requirement already satisfied: packaging in /home/user/.local/lib/python3.8/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/user/.local/lib/python3.8/site-packages (from tensorflow) (2.2.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/user/.local/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /home/user/.local/lib/python3.8/site-packages (from tensorflow) (2.11.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/user/.local/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/user/.local/lib/python3.8/site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in /home/user/.local/lib/python3.8/site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/user/.local/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/user/.local/lib/python3.8/site-packages (from tensorflow) (23.1.21)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/user/.local/lib/python3.8/site-packages (from tensorflow) (15.0.6.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/user/.local/lib/python3.8/site-packages (from tensorflow) (1.51.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/user/.local/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/user/.local/lib/python3.8/site-packages (from tensorflow) (1.23.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/user/.local/lib/python3.8/site-packages (from tensorflow) (3.8.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/user/.local/lib/python3.8/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /home/user/.local/lib/python3.8/site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/user/.local/lib/python3.8/site-packages (from tensorflow) (4.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/user/.local/lib/python3.8/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1; platform_machine != \"arm64\" or platform_system != \"Darwin\" in /home/user/.local/lib/python3.8/site-packages (from tensorflow) (0.30.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (45.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/user/.local/lib/python3.8/site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.34.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/user/.local/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/user/.local/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.16.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/user/.local/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/user/.local/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/user/.local/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/user/.local/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/user/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/user/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/user/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/user/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/user/.local/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /home/user/.local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (6.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/user/.local/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/user/.local/lib/python3.8/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imutils in /home/user/.local/lib/python3.8/site-packages (0.5.4)\n",
      "Requirement already satisfied: opencv-python in /home/user/.local/lib/python3.8/site-packages (4.7.0.68)\n",
      "Requirement already satisfied: numpy>=1.17.0; python_version >= \"3.7\" in /home/user/.local/lib/python3.8/site-packages (from opencv-python) (1.23.3)\n",
      "Requirement already satisfied: imageio in /home/user/.local/lib/python3.8/site-packages (2.25.0)\n",
      "Requirement already satisfied: numpy in /home/user/.local/lib/python3.8/site-packages (from imageio) (1.23.3)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /home/user/.local/lib/python3.8/site-packages (from imageio) (9.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install imutils\n",
    "!pip install opencv-python\n",
    "!pip install imageio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 23:35:47.970046: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-06 23:35:48.125455: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-06 23:35:48.125483: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-06 23:35:48.773561: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-06 23:35:48.773639: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-06 23:35:48.773649: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow_docs.vis import embed\n",
    "from tensorflow import keras\n",
    "from imutils import paths\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total videos for training: 24\n",
      "Total videos for testing: 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>video_name</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>dataset/train/Happy/Happy1.mp4</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>dataset/train/Happy/Happy7.mp4</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>dataset/train/Loss/Loss3.mp4</td>\n",
       "      <td>Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>dataset/train/Happy/Happy2.mp4</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>dataset/train/Goal/Goal2.MP4</td>\n",
       "      <td>Goal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>dataset/train/Happy/Happy4.mp4</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>dataset/train/Happy/Happy5.mp4</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>dataset/train/Loss/Loss6.mp4</td>\n",
       "      <td>Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>dataset/train/Loss/Loss5.mp4</td>\n",
       "      <td>Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>dataset/train/Goal/Goal6.mp4</td>\n",
       "      <td>Goal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                      video_name    tag\n",
       "12          12  dataset/train/Happy/Happy1.mp4  Happy\n",
       "17          17  dataset/train/Happy/Happy7.mp4  Happy\n",
       "23          23    dataset/train/Loss/Loss3.mp4   Loss\n",
       "16          16  dataset/train/Happy/Happy2.mp4  Happy\n",
       "2            2    dataset/train/Goal/Goal2.MP4   Goal\n",
       "11          11  dataset/train/Happy/Happy4.mp4  Happy\n",
       "9            9  dataset/train/Happy/Happy5.mp4  Happy\n",
       "20          20    dataset/train/Loss/Loss6.mp4   Loss\n",
       "22          22    dataset/train/Loss/Loss5.mp4   Loss\n",
       "5            5    dataset/train/Goal/Goal6.mp4   Goal"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "print(f\"Total videos for training: {len(train_df)}\")\n",
    "print(f\"Total videos for testing: {len(test_df)}\")\n",
    "\n",
    "\n",
    "train_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding video to the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "\n",
    "\n",
    "def crop_center_square(frame):\n",
    "    y, x = frame.shape[0:2]\n",
    "    min_dim = min(y, x)\n",
    "    start_x = (x // 2) - (min_dim // 2)\n",
    "    start_y = (y // 2) - (min_dim // 2)\n",
    "    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]\n",
    "\n",
    "\n",
    "def load_video(path, max_frames=0, resize=(IMG_SIZE, IMG_SIZE)):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = crop_center_square(frame)\n",
    "            frame = cv2.resize(frame, resize)\n",
    "            frame = frame[:, :, [2, 1, 0]]\n",
    "            frames.append(frame)\n",
    "\n",
    "            if len(frames) == max_frames:\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return np.array(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 23:36:11.039332: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/user/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-02-06 23:36:11.039365: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-06 23:36:11.039392: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (user-Vostro-3578): /proc/driver/nvidia/version does not exist\n",
      "2023-02-06 23:36:11.039650: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "def build_feature_extractor():\n",
    "    feature_extractor = keras.applications.InceptionV3(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        pooling=\"avg\",\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    )\n",
    "    preprocess_input = keras.applications.inception_v3.preprocess_input\n",
    "\n",
    "    inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
    "    preprocessed = preprocess_input(inputs)\n",
    "\n",
    "    outputs = feature_extractor(preprocessed)\n",
    "    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n",
    "\n",
    "\n",
    "feature_extractor = build_feature_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Goal', 'Happy', 'Loss']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_processor = keras.layers.StringLookup(num_oov_indices=0, vocabulary=np.unique(train_df[\"tag\"]))\n",
    "print(label_processor.get_vocabulary())\n",
    "\n",
    "labels = train_df[\"tag\"].values\n",
    "labels = label_processor(labels[..., None]).numpy()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define hyperparameters\n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "\n",
    "MAX_SEQ_LENGTH = 20\n",
    "NUM_FEATURES = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame features in train set: (24, 20, 2048)\n",
      "Frame masks in train set: (24, 20)\n",
      "train_labels in train set: (24, 1)\n",
      "test_labels in train set: (15, 1)\n"
     ]
    }
   ],
   "source": [
    "def prepare_all_videos(df, root_dir):\n",
    "    num_samples = len(df)\n",
    "    video_paths = df[\"video_name\"].values.tolist()\n",
    "    \n",
    "    ##take all classlabels from train_df column named 'tag' and store in labels\n",
    "    labels = df[\"tag\"].values\n",
    "    \n",
    "    #convert classlabels to label encoding\n",
    "    labels = label_processor(labels[..., None]).numpy()\n",
    "\n",
    "    # `frame_masks` and `frame_features` are what we will feed to our sequence model.\n",
    "    # `frame_masks` will contain a bunch of booleans denoting if a timestep is\n",
    "    # masked with padding or not.\n",
    "    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype=\"bool\") # 145,20\n",
    "    frame_features = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\") #145,20,2048\n",
    "\n",
    "    # For each video.\n",
    "    for idx, path in enumerate(video_paths):\n",
    "        # Gather all its frames and add a batch dimension.\n",
    "        frames = load_video(os.path.join(root_dir, path))\n",
    "        frames = frames[None, ...]\n",
    "\n",
    "        # Initialize placeholders to store the masks and features of the current video.\n",
    "        temp_frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "        temp_frame_features = np.zeros(\n",
    "            shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
    "        )\n",
    "\n",
    "        # Extract features from the frames of the current video.\n",
    "        for i, batch in enumerate(frames):\n",
    "            video_length = batch.shape[0]\n",
    "            length = min(MAX_SEQ_LENGTH, video_length)\n",
    "            for j in range(length):\n",
    "                temp_frame_features[i, j, :] = feature_extractor.predict(\n",
    "                    batch[None, j, :]\n",
    "                )\n",
    "            temp_frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
    "\n",
    "        frame_features[idx,] = temp_frame_features.squeeze()\n",
    "        frame_masks[idx,] = temp_frame_mask.squeeze()\n",
    "\n",
    "    return (frame_features, frame_masks), labels\n",
    "\n",
    "\n",
    "train_data, train_labels = prepare_all_videos(train_df, \"train\")\n",
    "test_data, test_labels = prepare_all_videos(test_df, \"test\")\n",
    "\n",
    "print(f\"Frame features in train set: {train_data[0].shape}\")\n",
    "print(f\"Frame masks in train set: {train_data[1].shape}\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"train_labels in train set: {train_labels.shape}\")\n",
    "\n",
    "print(f\"test_labels in train set: {test_labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.5625\n",
      "Epoch 1: val_loss improved from inf to 1.09945, saving model to ./tmp/video_classifier\n",
      "1/1 [==============================] - 10s 10s/step - loss: 1.0986 - accuracy: 0.5625 - val_loss: 1.0994 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0979 - accuracy: 0.5625\n",
      "Epoch 2: val_loss did not improve from 1.09945\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0979 - accuracy: 0.5625 - val_loss: 1.1003 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0973 - accuracy: 0.5625\n",
      "Epoch 3: val_loss did not improve from 1.09945\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.0973 - accuracy: 0.5625 - val_loss: 1.1011 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0966 - accuracy: 0.5625\n",
      "Epoch 4: val_loss did not improve from 1.09945\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.0966 - accuracy: 0.5625 - val_loss: 1.1020 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0960 - accuracy: 0.5625\n",
      "Epoch 5: val_loss did not improve from 1.09945\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.0960 - accuracy: 0.5625 - val_loss: 1.1028 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0953 - accuracy: 0.5625\n",
      "Epoch 6: val_loss did not improve from 1.09945\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.0953 - accuracy: 0.5625 - val_loss: 1.1036 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0946 - accuracy: 0.5625\n",
      "Epoch 7: val_loss did not improve from 1.09945\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0946 - accuracy: 0.5625 - val_loss: 1.1045 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0940 - accuracy: 0.5625\n",
      "Epoch 8: val_loss did not improve from 1.09945\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0940 - accuracy: 0.5625 - val_loss: 1.1053 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0933 - accuracy: 0.5625\n",
      "Epoch 9: val_loss did not improve from 1.09945\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.0933 - accuracy: 0.5625 - val_loss: 1.1061 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0927 - accuracy: 0.5625\n",
      "Epoch 10: val_loss did not improve from 1.09945\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.0927 - accuracy: 0.5625 - val_loss: 1.1070 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0920 - accuracy: 0.5625\n",
      "Epoch 11: val_loss did not improve from 1.09945\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.0920 - accuracy: 0.5625 - val_loss: 1.1078 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0913 - accuracy: 0.5625\n",
      "Epoch 12: val_loss did not improve from 1.09945\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.0913 - accuracy: 0.5625 - val_loss: 1.1087 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0907 - accuracy: 0.5625\n",
      "Epoch 13: val_loss did not improve from 1.09945\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.0907 - accuracy: 0.5625 - val_loss: 1.1095 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0900 - accuracy: 0.5625\n",
      "Epoch 14: val_loss did not improve from 1.09945\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.0900 - accuracy: 0.5625 - val_loss: 1.1104 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0894 - accuracy: 0.5625\n",
      "Epoch 15: val_loss did not improve from 1.09945\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0894 - accuracy: 0.5625 - val_loss: 1.1112 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0887 - accuracy: 0.5625\n",
      "Epoch 16: val_loss did not improve from 1.09945\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0887 - accuracy: 0.5625 - val_loss: 1.1120 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0881 - accuracy: 0.5625\n",
      "Epoch 17: val_loss did not improve from 1.09945\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.0881 - accuracy: 0.5625 - val_loss: 1.1129 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0874 - accuracy: 0.5625\n",
      "Epoch 18: val_loss did not improve from 1.09945\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0874 - accuracy: 0.5625 - val_loss: 1.1137 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0868 - accuracy: 0.5625\n",
      "Epoch 19: val_loss did not improve from 1.09945\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0868 - accuracy: 0.5625 - val_loss: 1.1146 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0861 - accuracy: 0.5625\n",
      "Epoch 20: val_loss did not improve from 1.09945\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.0861 - accuracy: 0.5625 - val_loss: 1.1154 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0855 - accuracy: 0.5625\n",
      "Epoch 21: val_loss did not improve from 1.09945\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.0855 - accuracy: 0.5625 - val_loss: 1.1163 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0848 - accuracy: 0.5625\n",
      "Epoch 22: val_loss did not improve from 1.09945\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.0848 - accuracy: 0.5625 - val_loss: 1.1171 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0842 - accuracy: 0.5625\n",
      "Epoch 23: val_loss did not improve from 1.09945\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.0842 - accuracy: 0.5625 - val_loss: 1.1180 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0835 - accuracy: 0.5625\n",
      "Epoch 24: val_loss did not improve from 1.09945\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.0835 - accuracy: 0.5625 - val_loss: 1.1188 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0829 - accuracy: 0.5625\n",
      "Epoch 25: val_loss did not improve from 1.09945\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.0829 - accuracy: 0.5625 - val_loss: 1.1197 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0823 - accuracy: 0.5625\n",
      "Epoch 26: val_loss did not improve from 1.09945\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.0823 - accuracy: 0.5625 - val_loss: 1.1205 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0816 - accuracy: 0.5625\n",
      "Epoch 27: val_loss did not improve from 1.09945\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.0816 - accuracy: 0.5625 - val_loss: 1.1214 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0810 - accuracy: 0.5625\n",
      "Epoch 28: val_loss did not improve from 1.09945\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.0810 - accuracy: 0.5625 - val_loss: 1.1222 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0803 - accuracy: 0.5625\n",
      "Epoch 29: val_loss did not improve from 1.09945\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.0803 - accuracy: 0.5625 - val_loss: 1.1231 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0797 - accuracy: 0.5625\n",
      "Epoch 30: val_loss did not improve from 1.09945\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.0797 - accuracy: 0.5625 - val_loss: 1.1239 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step - loss: 1.0986 - accuracy: 0.3333\n",
      "Test accuracy: 33.33%\n"
     ]
    }
   ],
   "source": [
    " #Utility for our sequence model.\n",
    "def get_sequence_model():\n",
    "    class_vocab = label_processor.get_vocabulary()\n",
    "\n",
    "    frame_features_input = keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n",
    "    mask_input = keras.Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "\n",
    "    # Refer to the following tutorial to understand the significance of using `mask`:\n",
    "    # https://keras.io/api/layers/recurrent_layers/gru/\n",
    "    x = keras.layers.GRU(16, return_sequences=True)(frame_features_input, mask=mask_input)\n",
    "    x = keras.layers.GRU(8)(x)\n",
    "    x = keras.layers.Dropout(0.4)(x)\n",
    "    x = keras.layers.Dense(8, activation=\"relu\")(x)\n",
    "    output = keras.layers.Dense(len(class_vocab), activation=\"softmax\")(x)\n",
    "\n",
    "    rnn_model = keras.Model([frame_features_input, mask_input], output)\n",
    "\n",
    "    rnn_model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return rnn_model\n",
    "\n",
    "EPOCHS = 30\n",
    "# Utility for running experiments.\n",
    "def run_experiment():\n",
    "    filepath = \"./tmp/video_classifier\"\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath, save_weights_only=True, save_best_only=True, verbose=1\n",
    "    )\n",
    "\n",
    "    seq_model = get_sequence_model()\n",
    "    history = seq_model.fit(\n",
    "        [train_data[0], train_data[1]],\n",
    "        train_labels,\n",
    "        validation_split=0.3,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[checkpoint],\n",
    "    )\n",
    "\n",
    "    seq_model.load_weights(filepath)\n",
    "    _, accuracy = seq_model.evaluate([test_data[0], test_data[1]], test_labels)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "\n",
    "    return history, seq_model\n",
    "\n",
    "\n",
    "_, sequence_model = run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test video path: dataset/test/Goal/Goal5.mp4\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "  Happy: 33.36%\n",
      "  Goal: 33.36%\n",
      "  Loss: 33.29%\n"
     ]
    }
   ],
   "source": [
    "def prepare_single_video(frames):\n",
    "    frames = frames[None, ...]\n",
    "    frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "    frame_features = np.zeros(shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n",
    "\n",
    "    for i, batch in enumerate(frames):\n",
    "        video_length = batch.shape[0]\n",
    "        length = min(MAX_SEQ_LENGTH, video_length)\n",
    "        for j in range(length):\n",
    "            frame_features[i, j, :] = feature_extractor.predict(batch[None, j, :])\n",
    "        frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
    "\n",
    "    return frame_features, frame_mask\n",
    "\n",
    "\n",
    "def sequence_prediction(path):\n",
    "    class_vocab = label_processor.get_vocabulary()\n",
    "\n",
    "    frames = load_video(os.path.join(\"test\", path))\n",
    "    frame_features, frame_mask = prepare_single_video(frames)\n",
    "    probabilities = sequence_model.predict([frame_features, frame_mask])[0]\n",
    "\n",
    "    for i in np.argsort(probabilities)[::-1]:\n",
    "        print(f\"  {class_vocab[i]}: {probabilities[i] * 100:5.2f}%\")\n",
    "    return frames\n",
    "\n",
    "test_video = np.random.choice(test_df[\"video_name\"].values.tolist())\n",
    "print(f\"Test video path: {test_video}\")\n",
    "\n",
    "test_frames = sequence_prediction(test_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"520\" height=\"440\" controls>\n",
       "  <source src=\"dataset/test/Goal/Goal5.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"\n",
    "<video width=\"520\" height=\"440\" controls>\n",
    "  <source src=\"dataset/test/Goal/Goal5.mp4\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
